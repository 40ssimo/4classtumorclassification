# -*- coding: utf-8 -*-
"""model_tumor_classification_4classes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i81Xmhpfs_ciBwIPmNXPOdgA_60d25Kl

###Setup
"""

import tensorflow as tf
import pathlib
import numpy as np
import os

from google.colab import drive
drive.mount('/content/drive')

#penentuan kelas
data_dir = pathlib.Path(r'/content/drive/MyDrive/dataset/train')
class_names = np.array(sorted([item.name for item in data_dir .glob("*")]))
class_names = class_names.tolist()
print(class_names)

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import random

#fungsi untuk melihat beberapa gambar secara acak
def view_random_image(target_dir, target_class):
  #setup the target directory (we'll view images from here)
  target_folder = target_dir+target_class

  #get a random image path
  random_image = random.sample(os.listdir(target_folder), 1)
  print(random_image)

  #read in the image and plot it using matplotlib
  img = mpimg.imread(target_folder + "/" + random_image[0])
  plt.imshow(img)
  plt.title(target_class)
  plt.axis("off");

  print(f"image shape: {img.shape}") #show the shape of the image
  return img

# melihat gambar dengan menggunakan fungsi sebelumnya
img = view_random_image(target_dir = r'/content/drive/MyDrive/dataset/train',
                        target_class = r"/pituitary")

"""###Preprocess"""

#--------------------
# Preprocess data
#--------------------

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# menentukan seed
tf.random.set_seed(42)

#preprocess untuk normalisasi data skala 0 sampai 1
train_datagen = ImageDataGenerator(rescale=1./255)
valid_datagen = ImageDataGenerator(rescale=1./255)

#setup paths to our data directories
train_dir = r"/content/drive/MyDrive/dataset/train"
val_dir = r"/content/drive/MyDrive/dataset/val"
test_dir  = r"/content/drive/MyDrive/dataset/test"

train_data = train_datagen.flow_from_directory(directory=train_dir,
                                              batch_size=16,
                                              target_size=(224,224),
                                              class_mode="categorical",
                                              shuffle=True,
                                              classes=class_names,
                                              seed=42)

valid_data = valid_datagen.flow_from_directory(directory=val_dir,
                                               batch_size=16,
                                               target_size=(224,224),
                                               class_mode="categorical",
                                               shuffle=False,
                                               classes=class_names,
                                               seed=42)

test_data = valid_datagen.flow_from_directory(directory=test_dir,
                                               batch_size=16,
                                               target_size=(224,224),
                                               class_mode="categorical",
                                              shuffle=False,
                                              classes=class_names,
                                               seed=42)

"""###Train Data"""

#------------------------------------------------------
# Perancangan model menggunakan transfer learning vgg16 
#------------------------------------------------------

from tensorflow.keras import layers 
from tensorflow.keras.applications.vgg16 import VGG16

#Input model VGG16
base_model = VGG16(input_shape = (224, 224, 3),
  include_top = False,
  weights = 'imagenet')

for layer in base_model.layers:
    layer.trainable = False #freeze layer, untuk feature extraction

class myCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if (logs.get('accuracy') > 0.90):
            print("\n Mencapai akurasi > 0.90, training berhenti")
            self.model.stop_training = True

callbacks = myCallback()

tf.keras.backend.clear_session()

#Variasi Model 1 (Non Augmented, LR = 0.01)

input = tf.keras.layers.Input(shape=(224, 224, 3), name="Input_layer")
x = base_model(input)
x = tf.keras.layers.Flatten()(x)
output = tf.keras.layers.Dense(4, activation='softmax', name="Output_Layer")(x)

model1 = tf.keras.models.Model(input, output, name="Model_1")

model1.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.01), loss = 'categorical_crossentropy', metrics = ['accuracy'])
vgghist1 = model1.fit(train_data, validation_data = valid_data, epochs = 100, callbacks= [callbacks])

model1.summary()

# melihat log aktivitas training
import pandas as pd
hist = pd.DataFrame(vgghist1.history) 
hist['epoch'] = vgghist1.epoch 
hist

model1.save('model1.h5')

tf.keras.backend.clear_session()

from tensorflow.keras.layers.experimental import preprocessing

#Variasi Model 2 (Non Augmented, LR = 0.001)

input = tf.keras.layers.Input(shape=(224, 224, 3), name="Input_layer")
x = base_model(input)
x = tf.keras.layers.Flatten()(x)
output = tf.keras.layers.Dense(4, activation='softmax', name="Output_Layer")(x)

model2 = tf.keras.models.Model(input, output, name="Model_2")

model2.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])
vgghist2 = model2.fit(train_data, validation_data = valid_data, epochs = 100, callbacks= [callbacks])

model2.summary()

# melihat log aktivitas training
import pandas as pd
hist = pd.DataFrame(vgghist2.history) 
hist['epoch'] = vgghist2.epoch 
hist

model2.save('model2.h5')

tf.keras.backend.clear_session()

from tensorflow.keras.layers.experimental import preprocessing

#Variasi Model 3 (Augmented = Random Rotation, LR = 0.01)

input = tf.keras.layers.Input(shape=(224, 224, 3), name="Input_layer")
x = preprocessing.RandomRotation(0.2)(input)
x = base_model(x)
x = tf.keras.layers.Flatten()(x)
output = tf.keras.layers.Dense(4, activation='softmax', name="Output_Layer")(x)

model3 = tf.keras.models.Model(input, output, name="Model_3")

model3.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.01), loss = 'categorical_crossentropy', metrics = ['accuracy'])
vgghist3 = model3.fit(train_data, validation_data = valid_data, epochs = 100, callbacks= [callbacks])

model3.summary()

# melihat log aktivitas training
import pandas as pd
hist = pd.DataFrame(vgghist3.history) 
hist['epoch'] = vgghist3.epoch 
hist

model3.save('model3.h5')

tf.keras.backend.clear_session()

from tensorflow.keras.layers.experimental import preprocessing

#Variasi Model 4 (Augmented = Random Rotation, LR = 0.001)

input = tf.keras.layers.Input(shape=(224, 224, 3), name="Input_layer")
x = preprocessing.RandomRotation(0.2)(input)
x = base_model(x)
x = tf.keras.layers.Flatten()(x)
output = tf.keras.layers.Dense(4, activation='softmax', name="Output_Layer")(x)

model4 = tf.keras.models.Model(input, output, name="Model_4")

model4.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])
vgghist4 = model4.fit(train_data, validation_data = valid_data, epochs = 100, callbacks= [callbacks])

model4.summary()

# melihat log aktivitas training
import pandas as pd
hist = pd.DataFrame(vgghist4.history) 
hist['epoch'] = vgghist4.epoch 
hist

model4.save('model4.h5')

tf.keras.backend.clear_session()

from tensorflow.keras.layers.experimental import preprocessing

#Variasi Model 5 (Augmented = Random Zoom, LR = 0.01)

input = tf.keras.layers.Input(shape=(224, 224, 3), name="Input_layer")
x = preprocessing.RandomZoom(0.2)(input)
x = base_model(x)
x = tf.keras.layers.Flatten()(x)
output = tf.keras.layers.Dense(4, activation='softmax', name="Output_Layer")(x)

model5 = tf.keras.models.Model(input, output, name="Model_5")

model5.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.01), loss = 'categorical_crossentropy', metrics = ['accuracy'])
vgghist5 = model5.fit(train_data, validation_data = valid_data, epochs = 100, callbacks= [callbacks])

model5.summary()

# melihat log aktivitas training
import pandas as pd
hist = pd.DataFrame(vgghist5.history) 
hist['epoch'] = vgghist5.epoch
hist

model5.save('model5.h5')

tf.keras.backend.clear_session()

from tensorflow.keras.layers.experimental import preprocessing

#Variasi Model 6 (Augmented = Random Zoom, LR = 0.001)

input = tf.keras.layers.Input(shape=(224, 224, 3), name="Input_layer")
x = preprocessing.RandomZoom(0.2)(input)
x = base_model(x)
x = tf.keras.layers.Flatten()(x)
output = tf.keras.layers.Dense(4, activation='softmax', name="Output_Layer")(x)

model6 = tf.keras.models.Model(input, output, name="Model_6")

model6.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])
vgghist6 = model6.fit(train_data, validation_data = valid_data, epochs = 100, callbacks= [callbacks])

model6.summary()

# melihat log aktivitas training
import pandas as pd
hist = pd.DataFrame(vgghist6.history) 
hist['epoch'] = vgghist6.epoch
hist

model6.save('model6.h5')

tf.keras.backend.clear_session()

from tensorflow.keras.layers.experimental import preprocessing

#Variasi Model 7 (Augmented = Random Flip "horizontal", LR = 0.01)

input = tf.keras.layers.Input(shape=(224, 224, 3), name="Input_layer")
x = preprocessing.RandomFlip("horizontal")(input)
x = base_model(x)
x = tf.keras.layers.Flatten()(x)
output = tf.keras.layers.Dense(4, activation='softmax', name="Output_Layer")(x)

model7 = tf.keras.models.Model(input, output, name="Model_7")

model7.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.01), loss = 'categorical_crossentropy', metrics = ['accuracy'])
vgghist7 = model7.fit(train_data, validation_data = valid_data, epochs = 100, callbacks= [callbacks])

model7.summary()

# melihat log aktivitas training
import pandas as pd
hist = pd.DataFrame(vgghist7.history) 
hist['epoch'] = vgghist7.epoch
hist

model7.save('model7.h5')

tf.keras.backend.clear_session()

from tensorflow.keras.layers.experimental import preprocessing

#Variasi Model 8 (Augmented = Random Flip "horizontal", LR = 0.001)

input = tf.keras.layers.Input(shape=(224, 224, 3), name="Input_layer")
x = preprocessing.RandomFlip("horizontal")(input)
x = base_model(x)
x = tf.keras.layers.Flatten()(x)
output = tf.keras.layers.Dense(4, activation='softmax', name="Output_Layer")(x)

model8 = tf.keras.models.Model(input, output, name="Model_8")

model8.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])
vgghist8 = model8.fit(train_data, validation_data = valid_data, epochs = 100, callbacks= [callbacks])

model8.summary()

# melihat log aktivitas training
import pandas as pd
hist = pd.DataFrame(vgghist8.history) 
hist['epoch'] = vgghist8.epoch
hist

model8.save('model8.h5')

tf.keras.backend.clear_session()

from tensorflow.keras.layers.experimental import preprocessing

#Variasi Model 9 (Augmented = Random Flip "vertical", LR = 0.01)

input = tf.keras.layers.Input(shape=(224, 224, 3), name="Input_layer")
x = preprocessing.RandomFlip("vertical")(input)
x = base_model(x)
x = tf.keras.layers.Flatten()(x)
output = tf.keras.layers.Dense(4, activation='softmax', name="Output_Layer")(x)

model9 = tf.keras.models.Model(input, output, name="Model_9")

model9.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.01), loss = 'categorical_crossentropy', metrics = ['accuracy'])
vgghist9 = model9.fit(train_data, validation_data = valid_data, epochs = 100, callbacks= [callbacks])

model9.summary()

# melihat log aktivitas training
import pandas as pd
hist = pd.DataFrame(vgghist9.history) 
hist['epoch'] = vgghist9.epoch
hist

model9.save('model9.h5')

tf.keras.backend.clear_session()

from tensorflow.keras.layers.experimental import preprocessing

#Variasi Model 10 (Augmented = Random Flip "vertical", LR = 0.001)

input = tf.keras.layers.Input(shape=(224, 224, 3), name="Input_layer")
x = preprocessing.RandomFlip("vertical")(input)
x = base_model(x)
x = tf.keras.layers.Flatten()(x)
output = tf.keras.layers.Dense(4, activation='softmax', name="Output_Layer")(x)

model10 = tf.keras.models.Model(input, output, name="Model_10")

model10.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])
vgghist10 = model10.fit(train_data, validation_data = valid_data, epochs = 100, callbacks= [callbacks])

model10.summary()

# melihat log aktivitas training
import pandas as pd
hist = pd.DataFrame(vgghist10.history) 
hist['epoch'] = vgghist10.epoch
hist

model10.save('model10.h5')

tf.keras.backend.clear_session()

from tensorflow.keras.layers.experimental import preprocessing

#Variasi Model 11 (Augmented = Random Rotation, Random Zoom, Random Flip V & H, LR = 0.01)

input = tf.keras.layers.Input(shape=(224, 224, 3), name="Input_layer")
x = preprocessing.RandomRotation(0.2)(input)
x = preprocessing.RandomZoom(0.2)(x)
x = preprocessing.RandomFlip("horizontal")(x)
x = preprocessing.RandomFlip("vertical")(x)
x = base_model(x)
x = tf.keras.layers.Flatten()(x)
output = tf.keras.layers.Dense(4, activation='softmax', name="Output_Layer")(x)

model11 = tf.keras.models.Model(input, output, name="Model_11")

model11.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.01), loss = 'categorical_crossentropy', metrics = ['accuracy'])
vgghist11 = model11.fit(train_data, validation_data = valid_data, epochs = 100, callbacks= [callbacks])

model11.summary()

model11.save('model11.h5')

# melihat log aktivitas training
import pandas as pd
hist = pd.DataFrame(vgghist11.history) 
hist['epoch'] = vgghist11.epoch
hist

tf.keras.backend.clear_session()

from tensorflow.keras.layers.experimental import preprocessing

#Variasi Model 12 (Augmented = Random Rotation, Random Zoom, Random Flip V & H, LR = 0.001)

input = tf.keras.layers.Input(shape=(224, 224, 3), name="Input_layer")
x = preprocessing.RandomRotation(0.2)(input)
x = preprocessing.RandomZoom(0.2)(x)
x = preprocessing.RandomFlip("horizontal")(x)
x = preprocessing.RandomFlip("vertical")(x)
x = base_model(x)
x = tf.keras.layers.Flatten()(x)
output = tf.keras.layers.Dense(4, activation='softmax', name="Output_Layer")(x)

model12 = tf.keras.models.Model(input, output, name="Model_12")

model12.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])
vgghist12 = model12.fit(train_data, validation_data = valid_data, epochs = 100, callbacks= [callbacks])

model12.summary()

# melihat log aktivitas training
import pandas as pd
hist = pd.DataFrame(vgghist12.history) 
hist['epoch'] = vgghist12.epoch
hist

model12.save('model12.h5')

"""###Predict dan Plot"""

def load_and_prep_image(filename, img_shape=224):
  """
  Reads an image from filename, turns it into a tensor
  and reshapes it to (img_shape, img_shape, colour_channel).
  """
  # Read in target file (an image)
  img = tf.io.read_file(filename)

  # Decode the read file into a tensor & ensure 3 colour channels 
  # (our model is trained on images with 3 colour channels and sometimes images have 4 colour channels)
  img = tf.image.decode_image(img, channels=3)

  # Resize the image (to the same size our model was trained on)
  img = tf.image.resize(img, size = [img_shape, img_shape])

  # Rescale the image (get all values between 0 and 1)
  img = img/255.
  return img

def pred_and_plot(model, file_path, class_names):
  """
  Imports an image located at filename, makes a prediction on it with
  a trained model and plots the image with the predicted class as the title.
  """
  # Import the target image and preprocess it
  img = load_and_prep_image(file_path)

  # Make a prediction
  pred = model.predict(tf.expand_dims(img, axis=0))

  # Get the predicted class
  pred_class = class_names[pred.argmax()]

  name = ""
  val_path  = "/content/drive/MyDrive/dataset/val/"
  test_path = "/content/drive/MyDrive/dataset/test/"
  kelas = ""
  for i in (file_path):
    if test_path in name:
      kelas += str(i)
      if "/" in kelas:
        break
    elif val_path in name:
      kelas += str(i)
      if "/" in kelas:
        break
    name += str(i)
  
  kelass = kelas.replace("/", "")

  # Plot the image and predicted class
  plt.imshow(img)
  plt.title(f"Prediction: {pred_class} \n Ground Truth : {kelass}")
  plt.axis(False);

"""###Confusion Matrix"""

# Note: The following confusion matrix code is a remix of Scikit-Learn's 
# plot_confusion_matrix function - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html
# and Made with ML's introductory notebook - https://github.com/GokuMohandas/MadeWithML/blob/main/notebooks/08_Neural_Networks.ipynb
import itertools
from sklearn.metrics import confusion_matrix

# Our function needs a different name to sklearn's plot_confusion_matrix
def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, model=None): 
  """Makes a labelled confusion matrix comparing predictions and ground truth labels.

  If classes is passed, confusion matrix will be labelled, if not, integer class values
  will be used.

  Args:
    y_true: Array of truth labels (must be same shape as y_pred).
    y_pred: Array of predicted labels (must be same shape as y_true).
    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.
    figsize: Size of output figure (default=(10, 10)).
    text_size: Size of output figure text (default=15).
  
  Returns:
    A labelled confusion matrix plot comparing y_true and y_pred.

  Example usage:
    make_confusion_matrix(y_true=test_labels, # ground truth test labels
                          y_pred=y_preds, # predicted labels
                          classes=class_names, # array of class label names
                          figsize=(15, 15),
                          text_size=10)
  """  
  # Create the confustion matrix
  cm = confusion_matrix(y_true, y_pred)
  cm_norm = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis] # normalize it
  n_classes = cm.shape[0] # find the number of classes we're dealing with

  # Plot the figure and make it pretty
  fig, ax = plt.subplots(figsize=figsize)
  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better
  fig.colorbar(cax)

  # Are there a list of classes?
  if classes:
    labels = classes
  else:
    labels = np.arange(cm.shape[0])
  
  # Label the axes
  ax.set(title="Confusion Matrix",
         xlabel="Predicted label",
         ylabel="True label",
         xticks=np.arange(n_classes), # create enough axis slots for each class
         yticks=np.arange(n_classes), 
         xticklabels=labels, # axes will labeled with class names (if they exist) or ints
         yticklabels=labels)
  
  # Make x-axis labels appear on bottom
  ax.xaxis.set_label_position("bottom")
  ax.xaxis.tick_bottom()

  # Set the threshold for different colors
  threshold = (cm.max() + cm.min()) / 2.

  # Plot the text on each cell
  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
    plt.text(j, i, f"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)",
             horizontalalignment="center",
             color="white" if cm[i, j] > threshold else "black",
             size=text_size)

"""###Validation Data"""

#Evaluation dengan validation data untuk 3 model terbaik (3, 6 dan 7)

model3.evaluate(valid_data, verbose=1)
model6.evaluate(valid_data, verbose=1)
model7.evaluate(valid_data, verbose=1)

#Prediksi dengan validation data menggunakan 3 model terbaik (Model 3, 6, dan 7)

prob_val3 = model3.predict(valid_data, verbose=1)
pred_val3 = prob_val3.argmax(axis=1)

prob_val6 = model6.predict(valid_data, verbose=1)
pred_val6 = prob_val6.argmax(axis=1)

prob_val7 = model7.predict(valid_data, verbose=1)
pred_val7 = prob_val7.argmax(axis=1)

#Membuat label untuk validasi

val_label = valid_data.classes
val_label = val_label.tolist()
print(val_label)

#Confusion Matrix untuk Model 3 menggunakan data validasi

make_confusion_matrix(y_true=val_label,
                      y_pred=pred_val3,
                      classes=class_names,
                      figsize=(10,10),
                      text_size=15)

#Confusion Matrix untuk Model 6 menggunakan data validasi

make_confusion_matrix(y_true=val_label,
                      y_pred=pred_val6,
                      classes=class_names,
                      figsize=(10,10),
                      text_size=15)

#Confusion Matrix untuk Model 7 menggunakan data validasi

make_confusion_matrix(y_true=val_label,
                      y_pred=pred_val7,
                      classes=class_names,
                      figsize=(10,10),
                      text_size=15)

#Classification report (Precision, Recall, F1, Support)

from sklearn.metrics import classification_report

print("Classification Report Model 3 : Validation Data")
print(classification_report(val_label, pred_val3, target_names=class_names))

print("Classification Report Model 6 : Validation Data")
print(classification_report(val_label, pred_val6, target_names=class_names))

print("Classification Report Model 7 : Validation Data")
print(classification_report(val_label, pred_val7, target_names=class_names))

"""###Pred dan Plot menggunakan validation data"""

#Mencoba pred dan plot pada model 3
pred_and_plot(model3, "/content/drive/MyDrive/dataset/val/normal/No11.jpg", class_names)

pred_and_plot(model3, "/content/drive/MyDrive/dataset/val/glioma/261.png", class_names)

pred_and_plot(model3, "/content/drive/MyDrive/dataset/val/meningioma/2461.png", class_names)

pred_and_plot(model3, "/content/drive/MyDrive/dataset/val/pituitary/948.png", class_names)

#Mencoba pred dan plot pada model 6
pred_and_plot(model6, "/content/drive/MyDrive/dataset/val/normal/No11.jpg", class_names)

pred_and_plot(model6, "/content/drive/MyDrive/dataset/val/glioma/261.png", class_names)

pred_and_plot(model6, "/content/drive/MyDrive/dataset/val/meningioma/2461.png", class_names)

pred_and_plot(model6, "/content/drive/MyDrive/dataset/val/pituitary/948.png", class_names)

#Mencoba pred dan plot pada model 7
pred_and_plot(model7, "/content/drive/MyDrive/dataset/val/normal/No11.jpg", class_names)

pred_and_plot(model7, "/content/drive/MyDrive/dataset/val/glioma/261.png", class_names)

pred_and_plot(model7, "/content/drive/MyDrive/dataset/val/meningioma/2461.png", class_names)

pred_and_plot(model7, "/content/drive/MyDrive/dataset/val/pituitary/948.png", class_names)

"""###Test Data"""

#Evaluation test data untuk 3 model terbaik (3, 6 dan 7)

model3.evaluate(test_data, verbose=1)
model6.evaluate(test_data, verbose=1)
model7.evaluate(test_data, verbose=1)

#Prediksi dengan test data menggunakan 3 model terbaik (Model 3, 6, dan 7)

prob_test3 = model3.predict(test_data, verbose=1)
pred_test3 = prob_test3.argmax(axis=1)

prob_test6 = model6.predict(test_data, verbose=1)
pred_test6 = prob_test6.argmax(axis=1)

prob_test7 = model7.predict(test_data, verbose=1)
pred_test7 = prob_test7.argmax(axis=1)

#Membuat label untuk test

test_label = test_data.classes
test_label = test_label.tolist()
print(test_label)

#Confusion Matrix untuk Model 3 menggunakan data test

make_confusion_matrix(y_true=test_label,
                      y_pred=pred_test3,
                      classes=class_names,
                      figsize=(10,10),
                      text_size=15)

#Confusion Matrix untuk Model 6 menggunakan data test

make_confusion_matrix(y_true=test_label,
                      y_pred=pred_test6,
                      classes=class_names,
                      figsize=(10,10),
                      text_size=15)

#Confusion Matrix untuk Model 7 menggunakan data test

make_confusion_matrix(y_true=test_label,
                      y_pred=pred_test7,
                      classes=class_names,
                      figsize=(10,10),
                      text_size=15)

#Classification report (Precision, Recall, F1)

from sklearn.metrics import classification_report

print("Classification Report Model 3 : Test Data")
print(classification_report(test_label, pred_test3, target_names=class_names))

print("Classification Report Model 6 : Test Data")
print(classification_report(test_label, pred_test6, target_names=class_names))

print("Classification Report Model 7 : Test Data")
print(classification_report(test_label, pred_test7, target_names=class_names))

"""### Pred dan Plot menggunakan test data"""

#Mencoba pred dan plot pada model 3
pred_and_plot(model3, "/content/drive/MyDrive/dataset/test/glioma/119.png", class_names)

pred_and_plot(model3, "/content/drive/MyDrive/dataset/test/meningioma/2417.png", class_names)

pred_and_plot(model3, "/content/drive/MyDrive/dataset/test/normal/no 9.png", class_names)

pred_and_plot(model3, "/content/drive/MyDrive/dataset/test/pituitary/926.png", class_names)

#Mencoba pred dan plot pada model 6
pred_and_plot(model6, "/content/drive/MyDrive/dataset/test/glioma/119.png", class_names)

pred_and_plot(model6, "/content/drive/MyDrive/dataset/test/meningioma/2417.png", class_names)

pred_and_plot(model6, "/content/drive/MyDrive/dataset/test/normal/no 9.png", class_names)

pred_and_plot(model6, "/content/drive/MyDrive/dataset/test/pituitary/926.png", class_names)

#Mencoba pred dan plot pada model 7
pred_and_plot(model7, "/content/drive/MyDrive/dataset/test/glioma/119.png", class_names)

pred_and_plot(model7, "/content/drive/MyDrive/dataset/test/meningioma/2417.png", class_names)

pred_and_plot(model7, "/content/drive/MyDrive/dataset/test/normal/no 9.png", class_names)

pred_and_plot(model7, "/content/drive/MyDrive/dataset/test/pituitary/926.png", class_names)